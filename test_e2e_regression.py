#!/usr/bin/env python3
"""
End-to-end regression test for itten spectral shader.

Compares THREE pipelines for cross-attention transfer:
  1. Original: spectral_shader_ops.two_image_shader_pass + spectral_ops_fast
  2. _cuter: spectral_shader_ops_cuter.two_image_shader_pass
  3. _even_cuter: SpectralCrossAttentionBlock (nn.Module)

Reference images were generated by demo_spectral_shader.py using Pipeline 1.

Known algorithmic differences (original vs _cuter/_even_cuter):
  1. Gradient finite difference: backward (original) vs forward (_cuter)
  2. Extra has_c * has_f guard gate in _cuter thickening (practically no-op)
  3. torch.lerp vs explicit multiply for compositing (float32 rounding)
  4. fill_empty_bins: loop (original) vs vectorized cummax/cummin (_cuter)

Fiedler computation:
  All three pipelines here use _cuter's compute_fiedler (evecs[:,:,1] from
  spectral_ops_fast_cuter.py) so that comparisons isolate shader op differences
  only. Pipeline 1 (Original) uses spectral_ops_fast.py's implementation which
  has a different Lanczos seed (hash-based vs n-based).

_cuter vs _even_cuter differences:
  The SpectralThickening module builds its Gaussian kernel on CPU (via
  register_buffer) then moves to CUDA, while the _cuter function builds
  the kernel directly on CUDA. For float32, kernel values are identical,
  but grid_sample with mode='nearest' can snap to different pixels when
  displacement is exactly at a pixel boundary. This creates sparse
  single-pixel outliers (max_abs can be large) but mean_abs is tiny.
  Under AR iteration, these sparse outliers compound because the Fiedler
  is recomputed on the (slightly different) mutated image.

PASS/FAIL criteria:
  - _cuter vs _even_cuter PASS 1: mean_abs < 1e-3 (near-identical)
  - _cuter vs _even_cuter ALL passes: mean_abs < 0.05 (AR drift tolerated)
  - Original vs reference: CHARACTERIZE only (CUDA non-determinism expected)
"""
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image

# ---- Pipeline 1: Original ----
from spectral_shader_ops import (
    two_image_shader_pass as original_two_image_shader_pass,
)
from spectral_ops_fast import compute_local_eigenvectors_tiled_dither

# ---- Pipeline 2: _even_cuter modules ----
from spectral_shader_model import SpectralCrossAttentionBlock

# ---- Pipeline 3: _cuter functions ----
from spectral_shader_ops_cuter import (
    two_image_shader_pass as cuter_two_image_shader_pass,
    _compute_fiedler_from_tensor as cuter_compute_fiedler,
)

# ---- Shared ----
from image_io import load_image


# ===================================================================
# Constants
# ===================================================================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
INPUT_DIR = Path("input_images")
OUTPUT_DIR = Path("demo_output/regression_test")

# ADSR envelope configs from demo_spectral_shader.py
ADSR_CONFIGS = [
    {"thicken_modulation": 0.2, "kernel_sigma_ratio": 0.8, "fill_threshold": 0.05, "dilation_radius": 3},
    {"thicken_modulation": 0.3, "kernel_sigma_ratio": 0.6, "fill_threshold": 0.1, "dilation_radius": 2},
    {"thicken_modulation": 0.5, "kernel_sigma_ratio": 0.5, "fill_threshold": 0.15, "dilation_radius": 2},
    {"thicken_modulation": 0.7, "kernel_sigma_ratio": 0.4, "fill_threshold": 0.2, "dilation_radius": 1},
]

BASE_CONFIG = {
    "effect_strength": 1.0,
    "gate_sharpness": 10.0,
    "translation_strength": 15.0,
    "shadow_offset": 5.0,
    "min_segment_pixels": 25,
    "max_segments": 40,
}

# Reference image paths
REFERENCE_PAIRS = {
    "tonegraph_x_snek": {
        "target": "red-tonegraph.png",
        "source": "snek-heavy.png",
        "refs": {
            1: "demo_output/tonegraph_x_snek_pass1_20260204_180308.png",
            2: "demo_output/tonegraph_x_snek_pass2_20260204_180309.png",
            3: "demo_output/tonegraph_x_snek_pass3_20260204_180310.png",
            4: "demo_output/tonegraph_x_snek_pass4_20260204_180311.png",
        },
        "final_ref": "demo_output/tonegraph_x_snek_final_20260204_180311.png",
    },
    "tonegraph_x_enso": {
        "target": "red-tonegraph.png",
        "source": "mspaint-enso-i-couldnt-forget.png",
        "refs": {
            1: "demo_output/tonegraph_x_enso_pass1_20260204_180314.png",
            2: "demo_output/tonegraph_x_enso_pass2_20260204_180314.png",
            3: "demo_output/tonegraph_x_enso_pass3_20260204_180315.png",
            4: "demo_output/tonegraph_x_enso_pass4_20260204_180316.png",
        },
        "final_ref": "demo_output/tonegraph_x_enso_final_20260204_180316.png",
    },
}

# Tolerances
PASS1_MEAN_ABS_TOL = 1e-3      # Pass 1: near-identical (float32 rounding only)
ALL_PASS_MEAN_ABS_TOL = 0.05   # All passes: AR drift tolerated


# ===================================================================
# Fiedler computation helpers
# ===================================================================

def compute_fiedler_original(img: torch.Tensor) -> torch.Tensor:
    """Compute Fiedler using original spectral_ops_fast (hash-based seed)."""
    evecs = compute_local_eigenvectors_tiled_dither(
        img, tile_size=64, overlap=16, num_eigenvectors=4
    )
    return evecs[:, :, 1]


def compute_fiedler_cuter(img: torch.Tensor) -> torch.Tensor:
    """Compute Fiedler using _cuter spectral_ops_fast_cuter (n-based seed)."""
    return cuter_compute_fiedler(img)


# ===================================================================
# Pipeline runners
# ===================================================================

def run_original_pipeline(
    img_A: torch.Tensor,
    img_B: torch.Tensor,
    n_passes: int = 4,
) -> List[torch.Tensor]:
    """Pipeline 1: Original code path (demo_spectral_shader.py).

    Uses original spectral_ops_fast for Fiedler computation and original
    spectral_shader_ops for the shader pass.
    """
    fiedler_B = compute_fiedler_original(img_B)
    current = img_A.clone()
    passes = []

    for i in range(n_passes):
        config = {**BASE_CONFIG, **ADSR_CONFIGS[min(i, 3)]}
        fiedler_current = compute_fiedler_original(current)
        result = original_two_image_shader_pass(
            image_A=current, image_B=img_B,
            fiedler_A=fiedler_current, fiedler_B=fiedler_B,
            config=config,
        )
        passes.append(result.clone())
        current = result

    return passes


def run_cuter_pipeline(
    img_A: torch.Tensor,
    img_B: torch.Tensor,
    n_passes: int = 4,
) -> List[torch.Tensor]:
    """Pipeline 3: _cuter functions directly.

    Uses _cuter's Fiedler computation and _cuter's shader pass.
    """
    fiedler_B = compute_fiedler_cuter(img_B)
    current = img_A.clone()
    passes = []

    for i in range(n_passes):
        config = {**BASE_CONFIG, **ADSR_CONFIGS[min(i, 3)]}
        fiedler_current = compute_fiedler_cuter(current)
        result = cuter_two_image_shader_pass(
            img_A=current, img_B=img_B,
            f_A=fiedler_current, f_B=fiedler_B,
            cfg=config,
        )
        passes.append(result.clone())
        current = result

    return passes


def run_even_cuter_pipeline(
    img_A: torch.Tensor,
    img_B: torch.Tensor,
    n_passes: int = 4,
) -> List[torch.Tensor]:
    """Pipeline 2: _even_cuter nn.Module pipeline.

    Uses _cuter's Fiedler computation (same as Pipeline 3) to isolate
    shader operation differences. SpectralCrossAttentionBlock wraps the
    same ops as _cuter's two_image_shader_pass.
    """
    fiedler_B = compute_fiedler_cuter(img_B)
    current = img_A.clone()
    passes = []

    for i in range(n_passes):
        adsr = ADSR_CONFIGS[min(i, 3)]
        config = {**BASE_CONFIG, **adsr}

        # Build per-pass cross-attention block with ADSR config
        block = SpectralCrossAttentionBlock(config).to(DEVICE)

        # Use same Fiedler as _cuter for fair comparison
        fiedler_current = compute_fiedler_cuter(current)

        # Run the block
        result = block(
            current,
            fiedler_current,
            source=img_B,
            source_fiedler=fiedler_B,
        )
        passes.append(result.clone())
        current = result

    return passes


# ===================================================================
# Comparison metrics
# ===================================================================

def compute_pixel_stats(
    a: torch.Tensor, b: torch.Tensor
) -> Dict[str, float]:
    """Compute pixel-level comparison statistics between two images."""
    diff = (a - b).abs()
    diff_per_pixel = diff.mean(dim=-1)

    max_abs = diff.max().item()
    mean_abs = diff.mean().item()
    rmse = torch.sqrt((diff ** 2).mean()).item()

    pct_any = (diff_per_pixel > 0).float().mean().item() * 100
    pct_visible = (diff_per_pixel > 5.0 / 255).float().mean().item() * 100
    pct_significant = (diff_per_pixel > 25.0 / 255).float().mean().item() * 100

    return {
        "max_abs": max_abs,
        "mean_abs": mean_abs,
        "rmse": rmse,
        "pct_any_diff": pct_any,
        "pct_visible": pct_visible,
        "pct_significant": pct_significant,
    }


def compute_spatial_analysis(
    a: torch.Tensor,
    b: torch.Tensor,
    gate: torch.Tensor,
    contours: torch.Tensor,
) -> Dict[str, float]:
    """Analyze WHERE differences are concentrated."""
    diff_mag = (a - b).abs().mean(dim=-1)

    if diff_mag.max() < 1e-8:
        return {
            "edge_correlation": 0.0,
            "high_gate_frac": 0.0,
            "low_gate_frac": 0.0,
            "spatial_autocorr": 0.0,
        }

    contour_f = contours.float()
    if contour_f.std() > 1e-8 and diff_mag.std() > 1e-8:
        edge_corr = torch.corrcoef(torch.stack([
            diff_mag.flatten(), contour_f.flatten()
        ]))[0, 1].item()
    else:
        edge_corr = 0.0

    high_gate_mask = gate > 0.5
    total_diff = diff_mag.sum()
    if total_diff > 1e-8:
        high_frac = diff_mag[high_gate_mask].sum().item() / total_diff.item()
        low_frac = diff_mag[~high_gate_mask].sum().item() / total_diff.item()
    else:
        high_frac = 0.0
        low_frac = 0.0

    if diff_mag.std() > 1e-8:
        shifted_r = torch.roll(diff_mag, 1, dims=1)
        shifted_d = torch.roll(diff_mag, 1, dims=0)
        auto_r = torch.corrcoef(torch.stack([
            diff_mag.flatten(), shifted_r.flatten()
        ]))[0, 1].item()
        auto_d = torch.corrcoef(torch.stack([
            diff_mag.flatten(), shifted_d.flatten()
        ]))[0, 1].item()
        spatial_auto = (auto_r + auto_d) / 2
    else:
        spatial_auto = 0.0

    return {
        "edge_correlation": edge_corr,
        "high_gate_frac": high_frac,
        "low_gate_frac": low_frac,
        "spatial_autocorr": spatial_auto,
    }


# ===================================================================
# Image I/O
# ===================================================================

def save_tensor_as_image(tensor: torch.Tensor, path: Path) -> None:
    """Save (H,W,3) float tensor as PNG without timestamps."""
    path.parent.mkdir(parents=True, exist_ok=True)
    arr = (tensor.detach().cpu().numpy() * 255).clip(0, 255).astype(np.uint8)
    Image.fromarray(arr).save(path)


def load_reference_image(path: str) -> Optional[torch.Tensor]:
    """Load a reference image, returning None if not found."""
    p = Path(path)
    if not p.exists():
        print(f"  WARNING: Reference image not found: {path}")
        return None
    img = Image.open(p).convert("RGB")
    arr = np.array(img).astype(np.float32) / 255.0
    return torch.from_numpy(arr).to(DEVICE)


def make_diff_visualization(a: torch.Tensor, b: torch.Tensor, amplify: float = 10.0) -> torch.Tensor:
    """Create an amplified difference map for visualization."""
    diff = (a - b).abs()
    return (diff * amplify).clamp(0, 1)


def make_heatmap(values: torch.Tensor) -> torch.Tensor:
    """Convert (H,W) scalar field to (H,W,3) blue-to-red heatmap."""
    v = values.clone()
    if v.max() > v.min():
        v = (v - v.min()) / (v.max() - v.min())
    else:
        v = torch.zeros_like(v)
    r = (2 * v).clamp(0, 1)
    b = (2 * (1 - v)).clamp(0, 1)
    g = 1 - 2 * (v - 0.5).abs()
    return torch.stack([r, g, b], dim=-1)


# ===================================================================
# Printing helpers
# ===================================================================

def print_header(text: str) -> None:
    print(f"\n{'=' * 72}")
    print(f"  {text}")
    print(f"{'=' * 72}")


def print_stats_table(
    label: str,
    stats_by_pass: List[Dict[str, float]],
) -> None:
    """Print a formatted stats table across passes."""
    print(f"\n  {label}")
    print(f"  {'Pass':<6} {'MaxAbs':>10} {'MeanAbs':>10} {'RMSE':>10} "
          f"{'%Any':>8} {'%Vis>5':>8} {'%Sig>25':>8}")
    print(f"  {'-' * 62}")
    for i, s in enumerate(stats_by_pass):
        def fmt(v, w=10):
            return f"{v:>{w}.6f}" if not np.isnan(v) else " " * (w - 3) + "N/A"
        def fmtp(v, w=7):
            return f"{v:>{w}.2f}%" if not np.isnan(v) else " " * (w - 2) + "N/A"
        print(f"  {i+1:<6} {fmt(s['max_abs'])} {fmt(s['mean_abs'])} {fmt(s['rmse'])} "
              f"{fmtp(s['pct_any_diff'])} {fmtp(s['pct_visible'])} {fmtp(s['pct_significant'])}")


def print_spatial_table(
    label: str,
    spatial_by_pass: List[Dict[str, float]],
) -> None:
    """Print spatial analysis table."""
    print(f"\n  {label}")
    print(f"  {'Pass':<6} {'EdgeCorr':>10} {'HighGate%':>10} {'LowGate%':>10} {'SpatAutoC':>10}")
    print(f"  {'-' * 50}")
    for i, s in enumerate(spatial_by_pass):
        print(f"  {i+1:<6} {s['edge_correlation']:>10.4f} "
              f"{s['high_gate_frac']*100:>9.1f}% {s['low_gate_frac']*100:>9.1f}% "
              f"{s['spatial_autocorr']:>10.4f}")


# ===================================================================
# Main test
# ===================================================================

def run_test_pair(
    pair_name: str,
    target_name: str,
    source_name: str,
    ref_paths: Dict[int, str],
    final_ref_path: str,
    n_passes: int = 4,
) -> Dict[str, bool]:
    """Run all three pipelines for one image pair and compare."""

    print_header(f"Testing: {pair_name} ({target_name} x {source_name})")

    img_A = load_image(INPUT_DIR / target_name, DEVICE)
    img_B = load_image(INPUT_DIR / source_name, DEVICE)
    print(f"  Target (A): {img_A.shape[1]}x{img_A.shape[0]}")
    print(f"  Source (B): {img_B.shape[1]}x{img_B.shape[0]}")

    test_pass = {}

    # ---- Pipeline 1: Original ----
    print("\n  [Pipeline 1] Original (spectral_shader_ops + spectral_ops_fast)")
    t0 = time.time()
    passes_original = run_original_pipeline(img_A, img_B, n_passes)
    t_original = time.time() - t0
    print(f"  Time: {t_original:.2f}s ({t_original / n_passes:.2f}s/pass)")

    # ---- Pipeline 3: _cuter ----
    print("\n  [Pipeline 3] _cuter (spectral_shader_ops_cuter)")
    t0 = time.time()
    passes_cuter = run_cuter_pipeline(img_A, img_B, n_passes)
    t_cuter = time.time() - t0
    print(f"  Time: {t_cuter:.2f}s ({t_cuter / n_passes:.2f}s/pass)")

    # ---- Pipeline 2: _even_cuter ----
    print("\n  [Pipeline 2] _even_cuter (nn.Module, same Fiedler as _cuter)")
    t0 = time.time()
    passes_even_cuter = run_even_cuter_pipeline(img_A, img_B, n_passes)
    t_even_cuter = time.time() - t0
    print(f"  Time: {t_even_cuter:.2f}s ({t_even_cuter / n_passes:.2f}s/pass)")

    # ---- Compute gate/contours for spatial analysis ----
    fiedler_A = compute_fiedler_cuter(img_A)
    from spectral_shader_ops_cuter import adaptive_threshold as cuter_adaptive_threshold
    from spectral_shader_ops_cuter import to_grayscale as cuter_to_grayscale
    from spectral_shader_ops_cuter import detect_contours as cuter_detect_contours
    thresh = cuter_adaptive_threshold(fiedler_A, 40.0)
    gate_A = torch.sigmoid((fiedler_A - thresh) * 10.0)
    gray_A = cuter_to_grayscale(img_A)
    contours_A = cuter_detect_contours(gray_A)

    # ================================================================
    # A. _cuter vs _even_cuter
    # ================================================================
    print_header(f"{pair_name}: _cuter vs _even_cuter")
    stats_ce = []
    spatial_ce = []
    for i in range(n_passes):
        s = compute_pixel_stats(passes_cuter[i], passes_even_cuter[i])
        stats_ce.append(s)
        sp = compute_spatial_analysis(passes_cuter[i], passes_even_cuter[i], gate_A, contours_A)
        spatial_ce.append(sp)

        diff_vis = make_diff_visualization(passes_cuter[i], passes_even_cuter[i], amplify=50.0)
        save_tensor_as_image(diff_vis, OUTPUT_DIR / f"{pair_name}_diff_cuter_vs_evencuter_pass{i+1}.png")

    print_stats_table("_cuter vs _even_cuter pixel stats:", stats_ce)
    if stats_ce[0]["mean_abs"] > 1e-6:
        print_spatial_table("_cuter vs _even_cuter spatial:", spatial_ce)

    # PASS 1 check: mean_abs should be near-zero (float rounding only)
    pass1_ok = stats_ce[0]["mean_abs"] < PASS1_MEAN_ABS_TOL
    # ALL passes check: AR drift tolerated but should stay bounded
    all_ok = all(s["mean_abs"] < ALL_PASS_MEAN_ABS_TOL for s in stats_ce)

    test_pass["cuter_vs_evencuter_pass1"] = pass1_ok
    test_pass["cuter_vs_evencuter_all"] = all_ok

    if pass1_ok:
        print(f"\n  Pass 1 mean_abs = {stats_ce[0]['mean_abs']:.8f} < {PASS1_MEAN_ABS_TOL}")
        print(f"  RESULT: PASS (pass 1 near-identical)")
    else:
        print(f"\n  Pass 1 mean_abs = {stats_ce[0]['mean_abs']:.8f} >= {PASS1_MEAN_ABS_TOL}")
        print(f"  RESULT: FAIL (pass 1 divergence too large)")

    if all_ok:
        print(f"  All passes mean_abs < {ALL_PASS_MEAN_ABS_TOL}: PASS")
    else:
        worst = max(s["mean_abs"] for s in stats_ce)
        print(f"  Worst mean_abs = {worst:.6f} >= {ALL_PASS_MEAN_ABS_TOL}: FAIL")

    # ================================================================
    # B. Original vs _cuter (characterize algorithm differences)
    # ================================================================
    print_header(f"{pair_name}: Original vs _cuter (characterize)")
    stats_oc = []
    spatial_oc = []
    for i in range(n_passes):
        s = compute_pixel_stats(passes_original[i], passes_cuter[i])
        stats_oc.append(s)
        sp = compute_spatial_analysis(passes_original[i], passes_cuter[i], gate_A, contours_A)
        spatial_oc.append(sp)

        diff_vis = make_diff_visualization(passes_original[i], passes_cuter[i], amplify=10.0)
        save_tensor_as_image(diff_vis, OUTPUT_DIR / f"{pair_name}_diff_original_vs_cuter_pass{i+1}.png")

        heatmap = make_heatmap((passes_original[i] - passes_cuter[i]).abs().mean(dim=-1))
        save_tensor_as_image(heatmap, OUTPUT_DIR / f"{pair_name}_spatial_diff_orig_vs_cuter_pass{i+1}.png")

    print_stats_table("Original vs _cuter pixel stats:", stats_oc)
    print_spatial_table("Original vs _cuter spatial:", spatial_oc)

    print(f"\n  Per-pass diff accumulation (Original vs _cuter):")
    print(f"  {'Pass':<6} {'MeanDiff':>12} {'Growth':>10}")
    print(f"  {'-' * 30}")
    for i in range(n_passes):
        d = stats_oc[i]["mean_abs"]
        if i == 0:
            growth = "baseline"
        else:
            prev = stats_oc[i-1]["mean_abs"]
            growth = f"{d / max(prev, 1e-8):.2f}x" if prev > 1e-8 else "inf"
        print(f"  {i+1:<6} {d:>12.6f} {growth:>10}")

    print("\n  RESULT: CHARACTERIZE (gradient shift + fill_empty_bins + Fiedler seed)")

    # ================================================================
    # C. Original vs _even_cuter (characterize)
    # ================================================================
    print_header(f"{pair_name}: Original vs _even_cuter (characterize)")
    stats_oe = []
    spatial_oe = []
    for i in range(n_passes):
        s = compute_pixel_stats(passes_original[i], passes_even_cuter[i])
        stats_oe.append(s)
        sp = compute_spatial_analysis(passes_original[i], passes_even_cuter[i], gate_A, contours_A)
        spatial_oe.append(sp)

        diff_vis = make_diff_visualization(passes_original[i], passes_even_cuter[i], amplify=10.0)
        save_tensor_as_image(diff_vis, OUTPUT_DIR / f"{pair_name}_diff_original_vs_evencuter_pass{i+1}.png")

        heatmap = make_heatmap((passes_original[i] - passes_even_cuter[i]).abs().mean(dim=-1))
        save_tensor_as_image(heatmap, OUTPUT_DIR / f"{pair_name}_spatial_diff_orig_vs_evencuter_pass{i+1}.png")

    print_stats_table("Original vs _even_cuter pixel stats:", stats_oe)
    print_spatial_table("Original vs _even_cuter spatial:", spatial_oe)
    print("\n  RESULT: CHARACTERIZE")

    # ================================================================
    # D. Original vs saved reference (characterize non-determinism)
    # ================================================================
    print_header(f"{pair_name}: Original vs Saved Reference (characterize)")
    ref_stats = []
    for pass_num, ref_path in sorted(ref_paths.items()):
        ref_img = load_reference_image(ref_path)
        if ref_img is None:
            ref_stats.append({"max_abs": float("nan"), "mean_abs": float("nan"),
                             "rmse": float("nan"), "pct_any_diff": float("nan"),
                             "pct_visible": float("nan"), "pct_significant": float("nan")})
            continue
        idx = pass_num - 1
        if idx < len(passes_original):
            s = compute_pixel_stats(passes_original[idx], ref_img)
            ref_stats.append(s)

    if ref_stats:
        print_stats_table("Original vs Reference:", ref_stats)
    print("\n  RESULT: CHARACTERIZE (CUDA non-determinism across runs)")

    # ================================================================
    # E. _even_cuter vs saved reference (characterize)
    # ================================================================
    print_header(f"{pair_name}: _even_cuter vs Saved Reference (characterize)")
    ec_ref_stats = []
    for pass_num, ref_path in sorted(ref_paths.items()):
        ref_img = load_reference_image(ref_path)
        if ref_img is None:
            ec_ref_stats.append({"max_abs": float("nan"), "mean_abs": float("nan"),
                                "rmse": float("nan"), "pct_any_diff": float("nan"),
                                "pct_visible": float("nan"), "pct_significant": float("nan")})
            continue
        idx = pass_num - 1
        if idx < len(passes_even_cuter):
            s = compute_pixel_stats(passes_even_cuter[idx], ref_img)
            ec_ref_stats.append(s)

    if ec_ref_stats:
        print_stats_table("_even_cuter vs Reference:", ec_ref_stats)
    print("\n  RESULT: CHARACTERIZE")

    # ---- Save pipeline outputs ----
    for i in range(n_passes):
        save_tensor_as_image(passes_original[i], OUTPUT_DIR / f"{pair_name}_original_pass{i+1}.png")
        save_tensor_as_image(passes_cuter[i], OUTPUT_DIR / f"{pair_name}_cuter_pass{i+1}.png")
        save_tensor_as_image(passes_even_cuter[i], OUTPUT_DIR / f"{pair_name}_evencuter_pass{i+1}.png")

    # ---- Timing summary ----
    print(f"\n  Timing: Original={t_original:.2f}s  _cuter={t_cuter:.2f}s  _even_cuter={t_even_cuter:.2f}s")

    return test_pass


# ===================================================================
# Entry point
# ===================================================================

def main() -> None:
    print(f"Device: {DEVICE}")
    print(f"Output: {OUTPUT_DIR}")
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    all_pass = {}
    total_start = time.time()

    for pair_name, info in REFERENCE_PAIRS.items():
        pair_results = run_test_pair(
            pair_name=pair_name,
            target_name=info["target"],
            source_name=info["source"],
            ref_paths=info["refs"],
            final_ref_path=info["final_ref"],
            n_passes=4,
        )
        for k, v in pair_results.items():
            all_pass[f"{pair_name}/{k}"] = v

    total_time = time.time() - total_start

    # ================================================================
    # Final summary
    # ================================================================
    print_header("FINAL SUMMARY")
    print(f"\n  Total time: {total_time:.1f}s")
    print(f"\n  Tolerances:")
    print(f"    Pass 1 mean_abs < {PASS1_MEAN_ABS_TOL} (float32 rounding)")
    print(f"    All passes mean_abs < {ALL_PASS_MEAN_ABS_TOL} (AR drift)")
    print()

    n_pass_count = sum(1 for v in all_pass.values() if v)
    n_fail = sum(1 for v in all_pass.values() if not v)
    n_total = len(all_pass)

    for test_name, passed in sorted(all_pass.items()):
        status = "PASS" if passed else "FAIL"
        print(f"  [{status}] {test_name}")

    print(f"\n  {n_pass_count}/{n_total} passed, {n_fail}/{n_total} failed")

    if n_fail > 0:
        print("\n  Failure notes:")
        print("    cuter_vs_evencuter_pass1 FAIL: SpectralThickening diverges from")
        print("      dilate_high_gate_fused at pass 1. Check Gaussian kernel construction")
        print("      or grid_sample nearest-neighbor boundary snapping.")
        print("    cuter_vs_evencuter_all FAIL: AR drift exceeds tolerance. The pass-1")
        print("      differences compound under autoregressive Fiedler recomputation.")

    print(f"\n  Diff images saved to: {OUTPUT_DIR}/")


if __name__ == "__main__":
    main()
